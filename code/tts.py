#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
OpenAI TTSë¥¼ ì‚¬ìš©í•œ ìŒì„± ìƒì„± ëª¨ë“ˆ

íŒŒì¼ëª… íŒ¨í„´ì„ ë¶„ì„í•˜ì—¬ í™”ìì™€ ë°œí™” ìœ í˜•ì— ë”°ë¼ 
ë‹¤ë¥¸ ìŒì„±ê³¼ í†¤ì„ ì ìš©í•˜ëŠ” TTS ì‹œìŠ¤í…œ
"""

import os
import sys
import argparse
from pathlib import Path
from typing import Tuple, Dict, Any

# OpenAI API ê´€ë ¨ ì„í¬íŠ¸
from openai import OpenAI
from dotenv import load_dotenv

# í˜„ì¬ íŒŒì¼ì˜ ë””ë ‰í† ë¦¬ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ê²½ë¡œ ì„¤ì •
BASE_DIR = Path(__file__).resolve().parent
PROJECT_ROOT = BASE_DIR.parent
ENV_FILE = PROJECT_ROOT / "resources" / ".env"

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv(ENV_FILE)

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    print("âŒ OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    sys.exit(1)

client = OpenAI(api_key=OPENAI_API_KEY)

# í™”ìë³„ ìŒì„± ì„¤ì •
VOICE_MAPPING = {
    "moderator": "nova",      # ì‚¬íšŒì: ì¤‘ì„±ì ì´ê³  ì•ˆì •ì ì¸ ëª©ì†Œë¦¬
    "optimistic": "alloy",    # ë‚™ê´€ë¡ ì: ë°ê³  ì—ë„ˆì§€ ë„˜ì¹˜ëŠ” ëª©ì†Œë¦¬  
    "pessimistic": "onyx",    # ì‹ ì¤‘ë¡ ì: ê¹Šê³  ì‹ ì¤‘í•œ ëª©ì†Œë¦¬
    "default": "shimmer"      # ê¸°ë³¸ê°’
}

# ë°œí™” ìœ í˜•ë³„ í†¤ ì¡°ì •ì„ ìœ„í•œ í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
TONE_ADJUSTMENTS = {
    "development": {
        "prefix": "",
        "speaking_rate": "normal",
        "emphasis": "analytical"
    },
    "response": {
        "prefix": "",
        "speaking_rate": "slightly_slower", 
        "emphasis": "conversational"
    },
    "summary": {
        "prefix": "",
        "speaking_rate": "normal",
        "emphasis": "conclusive"
    },
    "intro": {
        "prefix": "",
        "speaking_rate": "normal", 
        "emphasis": "welcoming"
    }
}


def parse_filename(file_path: str) -> Tuple[str, str]:
    """
    íŒŒì¼ëª…ì—ì„œ í™”ìì™€ ë°œí™” ìœ í˜•ì„ ì¶”ì¶œ
    
    Args:
        file_path: ì…ë ¥ íŒŒì¼ ê²½ë¡œ
        
    Returns:
        Tuple[speaker, speech_type]: í™”ìì™€ ë°œí™” ìœ í˜•
    """
    filename = Path(file_path).stem
    
    print(f"ğŸ” íŒŒì¼ëª… ë¶„ì„: {filename}")
    
    # ì¸íŠ¸ë¡œ íŒŒì¼ íŒ¨í„´: intro.txt, intro_1.txt
    if filename.startswith("intro"):
        return "moderator", "intro"
    
    # ì„¸ê·¸ë¨¼íŠ¸ íŒŒì¼ íŒ¨í„´: seg{num}_{speaker_code}_{type_code}_{flow}
    if filename.startswith("seg"):
        parts = filename.split("_")
        if len(parts) >= 4:
            speaker_code = parts[1]
            type_code = parts[2]
            
            # í™”ì ì½”ë“œ ë³€í™˜
            speaker_mapping = {
                "opt": "optimistic",
                "pes": "pessimistic", 
                "mod": "moderator"
            }
            
            # íƒ€ì… ì½”ë“œ ë³€í™˜
            type_mapping = {
                "dev": "development",
                "res": "response",
                "sum": "summary"
            }
            
            speaker = speaker_mapping.get(speaker_code, "default")
            speech_type = type_mapping.get(type_code, "development")
            
            print(f"  ğŸ“ ì„¸ê·¸ë¨¼íŠ¸ íŒŒì¼ - í™”ì: {speaker}, íƒ€ì…: {speech_type}")
            return speaker, speech_type
    
    # íŒ¨í„´ì„ ì¸ì‹í•  ìˆ˜ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ê°’
    print(f"  âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” íŒŒì¼ëª… íŒ¨í„´, ê¸°ë³¸ê°’ ì‚¬ìš©")
    return "default", "development"


def get_tts_instruction(speech_type: str, speaker: str) -> str:
    """
    í™”ìì™€ ë°œí™” ìœ í˜•ì— ë”°ë¥¸ TTS instruction ìƒì„±
    
    Args:
        speech_type: ë°œí™” ìœ í˜• (development, response, summary, intro)
        speaker: í™”ì (moderator, optimistic, pessimistic)
        
    Returns:
        str: TTS APIì— ì „ë‹¬í•  instruction
    """
    instructions = {
        "moderator": {
            "intro": "ìŒì„±ì„ ì¹œê·¼í•˜ê³  ì „ë¬¸ì ì¸ í†¤ìœ¼ë¡œ ì½ì–´ì£¼ì„¸ìš”. ì²­ì·¨ìë¥¼ í™˜ì˜í•˜ëŠ” ë”°ëœ»í•œ ëŠë‚Œìœ¼ë¡œ ë§í•˜ë˜, ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì§„í–‰ìì˜ ëª©ì†Œë¦¬ë¡œ ì•ˆì •ê° ìˆê²Œ ë°œìŒí•´ì£¼ì„¸ìš”.",
            "summary": "ì¤‘ë¦½ì ì´ê³  ì •ë¦¬í•˜ëŠ” í†¤ìœ¼ë¡œ ì½ì–´ì£¼ì„¸ìš”. ì•ì„  ë…¼ì˜ë¥¼ ì¢…í•©í•˜ì—¬ ë§ˆë¬´ë¦¬í•˜ëŠ” ëŠë‚Œìœ¼ë¡œ, ì°¨ë¶„í•˜ê³  ëª…í™•í•˜ê²Œ ë°œìŒí•´ì£¼ì„¸ìš”."
        },
        "optimistic": {
            "development": "í™•ì‹ ì— ì°¬ í†¤ìœ¼ë¡œ ì½ì–´ì£¼ì„¸ìš”. ê¸ì •ì ì¸ ë¶„ì„ì„ ì œì‹œí•˜ëŠ” ëŠë‚Œìœ¼ë¡œ í™œê¸°ì°¨ê³  ì„¤ë“ë ¥ ìˆê²Œ ë°œìŒí•´ì£¼ì„¸ìš”.",
            "response": "í™œê¸°ì°¬ í†¤ìœ¼ë¡œ ì½ì–´ì£¼ì„¸ìš”. ë°˜ë°•í•˜ê±°ë‚˜ ëŒ€ì‘í•˜ëŠ” ëŠë‚Œìœ¼ë¡œ ì—ë„ˆì§€ ë„˜ì¹˜ê³  ìì‹ ê° ìˆê²Œ ë°œìŒí•´ì£¼ì„¸ìš”.",
            "summary": "í¬ë§ì ì¸ í†¤ìœ¼ë¡œ ì½ì–´ì£¼ì„¸ìš”. ê¸ì •ì ì¸ ì „ë§ì„ ì œì‹œí•˜ëŠ” ëŠë‚Œìœ¼ë¡œ ë°ê³  ê²©ë ¤í•˜ëŠ” ë“¯ì´ ë°œìŒí•´ì£¼ì„¸ìš”."
        },
        "pessimistic": {
            "development": "ì‹ ì¤‘í•œ í†¤ìœ¼ë¡œ ì½ì–´ì£¼ì„¸ìš”. ë©´ë°€í•œ ë¶„ì„ì„ ì œì‹œí•˜ëŠ” ëŠë‚Œìœ¼ë¡œ ì°¨ë¶„í•˜ê³  ê¹Šì´ ìˆê²Œ ë°œìŒí•´ì£¼ì„¸ìš”.",
            "response": "ë…¼ë¦¬ì ì¸ í†¤ìœ¼ë¡œ ì½ì–´ì£¼ì„¸ìš”. ë°˜ë°•í•˜ê±°ë‚˜ ìš°ë ¤ì‚¬í•­ì„ ì œê¸°í•˜ëŠ” ëŠë‚Œìœ¼ë¡œ ì‹ ì¤‘í•˜ê³  ì„¤ë“ë ¥ ìˆê²Œ ë°œìŒí•´ì£¼ì„¸ìš”.",
            "summary": "ì‹ ì¤‘í•œ í†¤ìœ¼ë¡œ ì½ì–´ì£¼ì„¸ìš”. ë¦¬ìŠ¤í¬ë‚˜ ì£¼ì˜ì‚¬í•­ì„ ê°•ì¡°í•˜ëŠ” ëŠë‚Œìœ¼ë¡œ ì°¨ë¶„í•˜ê³  ì§„ì¤‘í•˜ê²Œ ë°œìŒí•´ì£¼ì„¸ìš”."
        }
    }
    
    # instruction ì¡°íšŒ ë° ê¸°ë³¸ê°’ ì²˜ë¦¬
    speaker_instructions = instructions.get(speaker, instructions["moderator"])
    instruction = speaker_instructions.get(speech_type, "ìì—°ìŠ¤ëŸ½ê³  ëª…í™•í•œ í†¤ìœ¼ë¡œ ì½ì–´ì£¼ì„¸ìš”.")
    
    return instruction


def adjust_text(text: str, speech_type: str, speaker: str) -> str:
    """
    ë°œí™” ìœ í˜•ê³¼ í™”ìì— ë”°ë¼ í…ìŠ¤íŠ¸ë¥¼ ì¡°ì •
    
    Args:
        text: ì›ë³¸ í…ìŠ¤íŠ¸
        speech_type: ë°œí™” ìœ í˜• (development, response, summary, intro)
        speaker: í™”ì (moderator, optimistic, pessimistic)
        
    Returns:
        str: ì¡°ì •ëœ í…ìŠ¤íŠ¸
    """
    # ê¸°ë³¸ì ìœ¼ë¡œ í…ìŠ¤íŠ¸ ì •ë¦¬
    adjusted_text = text.strip()
    
    # í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ (í•„ìš”ì‹œ ì¶”ê°€)
    # ì˜ˆ: íŠ¹ìˆ˜ ë¬¸ì ì²˜ë¦¬, ë°œìŒí•˜ê¸° ì–´ë ¤ìš´ ìš©ì–´ êµì²´ ë“±
    
    return adjusted_text


def generate_speech(text: str, voice: str, output_path: str, instruction: str = "") -> bool:
    """
    OpenAI TTS APIë¥¼ ì‚¬ìš©í•˜ì—¬ ìŒì„± ìƒì„±
    
    Args:
        text: ë³€í™˜í•  í…ìŠ¤íŠ¸
        voice: ì‚¬ìš©í•  ìŒì„±
        output_path: ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
        instruction: TTS ìŠ¤íƒ€ì¼ instruction
        
    Returns:
        bool: ì„±ê³µ ì—¬ë¶€
    """
    try:
        print(f"ğŸ”Š TTS ìƒì„± ì‹œì‘...")
        print(f"  ğŸ“ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(text)} ê¸€ì")
        print(f"  ğŸµ ìŒì„±: {voice}")
        print(f"  ğŸ­ instruction: {instruction[:50]}..." if len(instruction) > 50 else f"  ğŸ­ instruction: {instruction}")
        print(f"  ğŸ“ ì¶œë ¥: {output_path}")
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        output_dir = Path(output_path).parent
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # OpenAI TTS API í˜¸ì¶œ (gpt-4o-mini-tts ëª¨ë¸ì€ instruction íŒŒë¼ë¯¸í„° ì§€ì›)
        speech_file_path = Path(output_path)
        
        # API í˜¸ì¶œ íŒŒë¼ë¯¸í„° êµ¬ì„±
        api_params = {
            "model": "gpt-4o-mini-tts",
            "voice": voice,
            "input": text
        }
        
        # # instructionì´ ìˆìœ¼ë©´ íŒŒë¼ë¯¸í„°ì— ì¶”ê°€.. ì™œì¸ì§€ëŠ” ëª¨ë¥´ê² ìœ¼ë‚˜ instructionì´ ìˆìœ¼ë©´ ì•ˆ ë˜ëŠ” ë“¯...?
        # if instruction:
        #     api_params["instruction"] = instruction
        
        with client.audio.speech.with_streaming_response.create(**api_params) as response:
            response.stream_to_file(speech_file_path)
        
        print(f"âœ… TTS ìƒì„± ì™„ë£Œ: {output_path}")
        return True
        
    except Exception as e:
        print(f"âŒ TTS ìƒì„± ì‹¤íŒ¨: {e}")
        return False


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description="í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜")
    parser.add_argument("--input", required=True, help="ì…ë ¥ í…ìŠ¤íŠ¸ íŒŒì¼ ê²½ë¡œ")
    parser.add_argument("--output", required=True, help="ì¶œë ¥ ìŒì„± íŒŒì¼ ê²½ë¡œ")
    
    args = parser.parse_args()
    
    input_path = args.input
    output_path = args.output
    
    print("ğŸ¯ TTS ë³€í™˜ ì‹œì‘")
    print(f"ğŸ“„ ì…ë ¥ íŒŒì¼: {input_path}")
    print(f"ğŸ”Š ì¶œë ¥ íŒŒì¼: {output_path}")
    
    # ì…ë ¥ íŒŒì¼ ì¡´ì¬ í™•ì¸
    if not Path(input_path).exists():
        print(f"âŒ ì…ë ¥ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {input_path}")
        sys.exit(1)
    
    try:
        # í…ìŠ¤íŠ¸ íŒŒì¼ ì½ê¸°
        with open(input_path, 'r', encoding='utf-8') as f:
            text = f.read().strip()
        
        if not text:
            print("âŒ ì…ë ¥ íŒŒì¼ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            sys.exit(1)
        
        # íŒŒì¼ëª…ì—ì„œ í™”ìì™€ ë°œí™” ìœ í˜• ì¶”ì¶œ
        speaker, speech_type = parse_filename(input_path)
        
        # í™”ìì— ë”°ë¥¸ ìŒì„± ì„ íƒ
        voice = VOICE_MAPPING.get(speaker, VOICE_MAPPING["default"])
        
        # í™”ìì™€ ë°œí™” ìœ í˜•ì— ë”°ë¥¸ instruction ìƒì„±
        instruction = get_tts_instruction(speech_type, speaker)
        
        print(f"ğŸ­ í™”ì: {speaker}")
        print(f"ğŸ’¬ ë°œí™” ìœ í˜•: {speech_type}")
        print(f"ğŸµ ì„ íƒëœ ìŒì„±: {voice}")
        print(f"ğŸ“‹ instruction: {instruction[:100]}..." if len(instruction) > 100 else f"ğŸ“‹ instruction: {instruction}")
        
        # í…ìŠ¤íŠ¸ ì¡°ì •
        adjusted_text = adjust_text(text, speech_type, speaker)
        
        # TTS ìƒì„± (instruction í¬í•¨)
        success = generate_speech(adjusted_text, voice, output_path, instruction)
        
        if success:
            print("ğŸ‰ TTS ë³€í™˜ ì™„ë£Œ!")
            sys.exit(0)
        else:
            print("âŒ TTS ë³€í™˜ ì‹¤íŒ¨!")
            sys.exit(1)
            
    except Exception as e:
        print(f"âŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()